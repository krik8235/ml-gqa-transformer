[project]
name = "src"
version = "0.1.0"
authors = [{ name = "Kuriko Iwai", email = "krik8235@gmail.com" }]
description = "code implementation for arXiv:2412.20677 Align Attention Heads Before Merging Them: An Effective Way for Converting MHA to GQA"
readme = "README.md"
requires-python = "==3.12.*"
classifiers = ["Programming Language :: Python"]
dependencies = [
    "torch>=2.9.1",
    "transformers>=4.57.1",
]

[project.urls]
Repository = "https://github.com/krik8235/ml-gqa-transformer"
Issues = "https://github.com/krik8235/ml-gqa-transformer/issues"

[project.optional-dependencies]


[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["src"]

[tool.black]
line-length = 88

[tool.isort]
profile = "black"

[tool.uv]
package = true

[tool.uv.workspace]
members = ["kuriko"]

[tool.mypy]
ignore_missing_imports = true

[tool.bandit]
exclude_dirs = [""]

[dependency-groups]
dev = [
]
